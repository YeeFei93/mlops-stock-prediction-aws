AWSTemplateFormatVersion: '2010-09-09'
Description: 'MLOps Stock Prediction Pipeline - Cost-Optimized Infrastructure'

Parameters:
  Environment:
    Type: String
    Default: 'dev'
    AllowedValues: ['dev', 'staging', 'prod']
    Description: Environment name
  
  S3BucketName:
    Type: String
    Default: 'mlops-stock-data'
    Description: S3 bucket for data storage

Resources:
  # Instance Profile for EC2 instances in Batch Compute Environment
  BatchInstanceProfile:
    Type: AWS::IAM::InstanceProfile
    Properties:
      Roles:
        - !Ref BatchInstanceRole
      Path: /
  # IAM Role for EC2 instances in Batch Compute Environment
  BatchInstanceRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: ec2.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AmazonEC2ContainerServiceforEC2Role
      Path: /
      Tags:
        - Key: Name
          Value: mlops-batch-ec2-role
  # VPC for Batch Compute Environment
  MyVPC:
    Type: AWS::EC2::VPC
    Properties:
      CidrBlock: 10.0.0.0/16
      EnableDnsSupport: true
      EnableDnsHostnames: true
      Tags:
        - Key: Name
          Value: mlops-vpc

  # Subnet for Batch Compute Environment
  MySubnet:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref MyVPC
      CidrBlock: 10.0.1.0/24
      AvailabilityZone: us-east-1a
      Tags:
        - Key: Name
          Value: mlops-subnet
  # S3 Bucket for data storage
  DataBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub '${S3BucketName}-${AWS::AccountId}-${AWS::Region}'
      VersioningConfiguration:
        Status: Enabled
      LifecycleConfiguration:
        Rules:
          - Id: DataLifecycle
            Status: Enabled
            Transitions:
              - TransitionInDays: 30
                StorageClass: STANDARD_IA
              - TransitionInDays: 90
                StorageClass: GLACIER
              - TransitionInDays: 365
                StorageClass: DEEP_ARCHIVE
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true

  # ECR Repository
  ECRRepository:
    Type: AWS::ECR::Repository
    Properties:
      RepositoryName: mlops-stock-prediction
      LifecyclePolicy:
        LifecyclePolicyText: |
          {
            "rules": [
              {
                "rulePriority": 1,
                "selection": {
                  "tagStatus": "untagged",
                  "countType": "sinceImagePushed",
                  "countUnit": "days",
                  "countNumber": 7
                },
                "action": {
                  "type": "expire"
                }
              }
            ]
          }

  # Lambda Execution Role
  LambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Policies:
        - PolicyName: S3Access
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:PutObject
                  - s3:ListBucket
                Resource:
                  - !GetAtt DataBucket.Arn
                  - !Sub 'arn:aws:s3:::${S3BucketName}-${AWS::AccountId}-${AWS::Region}/*'

  # Data Collection Lambda
  DataCollectionLambda:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub 'stock-data-collector-${Environment}'
      Runtime: python3.9
      Handler: stock_data_collector.lambda_handler
      Code:
        ZipFile: |
          import json
          def lambda_handler(event, context):
              return {'statusCode': 200, 'body': json.dumps('Placeholder function')}
      Role: !GetAtt LambdaExecutionRole.Arn
      Timeout: 300
      MemorySize: 512
      Environment:
        Variables:
          S3_BUCKET: !Ref DataBucket
      ReservedConcurrentExecutions: 5

  # Inference Lambda
  InferenceLambda:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub 'stock-prediction-api-${Environment}'
      Runtime: python3.9
      Handler: predict_api.lambda_handler
      Code:
        ZipFile: |
          import json
          def lambda_handler(event, context):
              return {'statusCode': 200, 'body': json.dumps('Placeholder function')}
      Role: !GetAtt LambdaExecutionRole.Arn
      Timeout: 30
      MemorySize: 1024
      Environment:
        Variables:
          S3_BUCKET: !Ref DataBucket
      ReservedConcurrentExecutions: 10

  # EventBridge rule for scheduled data collection
  DataCollectionSchedule:
    Type: AWS::Events::Rule
    Properties:
      Description: 'Trigger data collection daily'
      ScheduleExpression: 'cron(0 9 * * ? *)'  # 9 AM UTC daily
      State: ENABLED
      Targets:
        - Arn: !GetAtt DataCollectionLambda.Arn
          Id: DataCollectionTarget
          Input: |
            {
              "symbols": ["AAPL", "GOOGL", "MSFT", "TSLA", "AMZN"]
            }

  # Permission for EventBridge to invoke Lambda
  DataCollectionPermission:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !Ref DataCollectionLambda
      Action: lambda:InvokeFunction
      Principal: events.amazonaws.com
      SourceArn: !GetAtt DataCollectionSchedule.Arn

  # API Gateway for inference
  ApiGateway:
    Type: AWS::ApiGateway::RestApi
    Properties:
      Name: !Sub 'stock-prediction-api-${Environment}'
      Description: 'Stock prediction API'
      EndpointConfiguration:
        Types:
          - EDGE

  # API Gateway Resource
  ApiResource:
    Type: AWS::ApiGateway::Resource
    Properties:
      RestApiId: !Ref ApiGateway
      ParentId: !GetAtt ApiGateway.RootResourceId
      PathPart: 'predict'

  # API Gateway Method
  ApiMethod:
    Type: AWS::ApiGateway::Method
    Properties:
      RestApiId: !Ref ApiGateway
      ResourceId: !Ref ApiResource
      HttpMethod: POST
      AuthorizationType: NONE
      Integration:
        Type: AWS_PROXY
        IntegrationHttpMethod: POST
        Uri: !Sub 'arn:aws:apigateway:${AWS::Region}:lambda:path/2015-03-31/functions/${InferenceLambda.Arn}/invocations'

  # Permission for API Gateway to invoke Lambda
  ApiGatewayPermission:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !Ref InferenceLambda
      Action: lambda:InvokeFunction
      Principal: apigateway.amazonaws.com
      SourceArn: !Sub '${ApiGateway}/*/*'

  # API Gateway Deployment
  ApiDeployment:
    Type: AWS::ApiGateway::Deployment
    DependsOn: ApiMethod
    Properties:
      RestApiId: !Ref ApiGateway
      StageName: !Ref Environment

  # Batch Compute Environment for training
  BatchComputeEnvironment:
    Type: AWS::Batch::ComputeEnvironment
    Properties:
      Type: MANAGED
      State: ENABLED
      ServiceRole: !GetAtt BatchServiceRole.Arn
      ComputeResources:
        Type: EC2
        MinvCpus: 0
        MaxvCpus: 16
        DesiredvCpus: 0
        InstanceTypes: ['optimal']
        BidPercentage: 50  # Use Spot instances for 50% cost savings
        InstanceRole: !Ref BatchInstanceProfile
        Subnets:
          - !Ref MySubnet
        Tags:
          Name: !Sub 'mlops-batch-${Environment}'
          Environment: !Ref Environment

  # Batch Service Role
  BatchServiceRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: batch.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSBatchServiceRole

  # Batch Job Queue
  BatchJobQueue:
    Type: AWS::Batch::JobQueue
    Properties:
      ComputeEnvironmentOrder:
        - Order: 1
          ComputeEnvironment: !Ref BatchComputeEnvironment
      Priority: 1
      State: ENABLED

  # CloudWatch Dashboard
  Dashboard:
    Type: AWS::CloudWatch::Dashboard
    Properties:
      DashboardName: !Sub 'MLOps-StockPrediction-${Environment}'
      DashboardBody: !Sub |
        {
          "widgets": [
            {
              "type": "metric",
              "x": 0,
              "y": 0,
              "width": 12,
              "height": 6,
              "properties": {
                "metrics": [
                  [ "AWS/Lambda", "Duration", "FunctionName", "${InferenceLambda}" ],
                  [ ".", "Errors", ".", "." ],
                  [ ".", "Invocations", ".", "." ]
                ],
                "period": 300,
                "stat": "Average",
                "region": "${AWS::Region}",
                "title": "Lambda Metrics"
              }
            }
          ]
        }

Outputs:
  ApiUrl:
    Description: 'API Gateway endpoint URL'
    Value: !Sub 'https://${ApiGateway}.execute-api.${AWS::Region}.amazonaws.com/${Environment}/predict'
    Export:
      Name: !Sub '${AWS::StackName}-ApiUrl'

  S3Bucket:
    Description: 'S3 bucket name'
    Value: !Ref DataBucket
    Export:
      Name: !Sub '${AWS::StackName}-S3Bucket'

  ECRRepository:
    Description: 'ECR repository URI'
    Value: !Sub '${AWS::AccountId}.dkr.ecr.${AWS::Region}.amazonaws.com/${ECRRepository}'
    Export:
      Name: !Sub '${AWS::StackName}-ECRRepository'
