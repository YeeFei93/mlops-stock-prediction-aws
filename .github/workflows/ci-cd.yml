name: MLOps Stock Prediction CI/CD

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

env:
  AWS_REGION: us-east-1
  ECR_REPOSITORY: mlops-stock-prediction
  S3_BUCKET: mlops-stock-data-${{ github.run_id }}

jobs:
  test:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov
    
    - name: Run tests
      run: |
        pytest tests/ --cov=src --cov-report=xml
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml

  build-and-deploy:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}
    
    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v1
    
    - name: Build, tag, and push image to Amazon ECR
      env:
        ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        IMAGE_TAG: ${{ github.sha }}
      run: |
        docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG .
        docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG
        docker tag $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG $ECR_REGISTRY/$ECR_REPOSITORY:latest
        docker push $ECR_REGISTRY/$ECR_REPOSITORY:latest
    
    - name: Deploy Lambda functions
      run: |
        # Package and deploy data ingestion Lambda
        cd src/data_ingestion
        zip -r ../../data-ingestion-lambda.zip . -x "__pycache__/*"
        cd ../..
        
        # Package and deploy inference Lambda
        cd src/inference
        zip -r ../../inference-lambda.zip . -x "__pycache__/*"
        cd ../..
        
        # Deploy with AWS CLI (you can also use SAM or Terraform)
        aws lambda update-function-code \
          --function-name stock-data-collector \
          --zip-file fileb://data-ingestion-lambda.zip \
          --region $AWS_REGION || true
          
        aws lambda update-function-code \
          --function-name stock-prediction-api \
          --zip-file fileb://inference-lambda.zip \
          --region $AWS_REGION || true
    
    - name: Update EKS deployment
      env:
        ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        IMAGE_TAG: ${{ github.sha }}
      run: |
        # Update Kubernetes deployment with new image
        aws eks update-kubeconfig --region $AWS_REGION --name mlops-cluster
        kubectl set image deployment/stock-training-job \
          stock-training=$ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG
        kubectl rollout status deployment/stock-training-job

  infrastructure:
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' && contains(github.event.head_commit.message, '[deploy-infra]')
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}
    
    - name: Deploy CloudFormation stack
      run: |
        aws cloudformation deploy \
          --template-file infrastructure/cloudformation-template.yaml \
          --stack-name mlops-stock-prediction-stack \
          --parameter-overrides \
            Environment=prod \
            S3BucketName=$S3_BUCKET \
          --capabilities CAPABILITY_IAM \
          --region $AWS_REGION
